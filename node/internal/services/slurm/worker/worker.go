package worker

import (
	"context"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"syscall"
	"time"

	"github.com/cluster-os/node/internal/roles"
	"github.com/cluster-os/node/internal/services/slurm/auth"
	"github.com/cluster-os/node/internal/state"
	"github.com/sirupsen/logrus"
)

// SLURMWorker implements the SLURM worker role
type SLURMWorker struct {
	*roles.BaseRole
	config          *Config
	clusterState    *state.ClusterState
	slurmdCmd       *exec.Cmd
	mungeKeyManager *auth.MungeKeyManager
	configPath      string
	spoolPath       string
}

// Config contains configuration for the SLURM worker
type Config struct {
	ConfigPath    string
	SpoolPath     string
	SlurmConfPath string
}

// NewSLURMWorker creates a new SLURM worker role
func NewSLURMWorker(roleConfig *roles.RoleConfig, logger *logrus.Logger) (roles.Role, error) {
	config := &Config{
		ConfigPath:    "/etc/slurm",
		SpoolPath:     "/var/lib/slurm/slurmd",
		SlurmConfPath: "/etc/slurm/slurm.conf",
	}

	// Override from role config
	if val, ok := roleConfig.Config["config_path"].(string); ok {
		config.ConfigPath = val
	}
	if val, ok := roleConfig.Config["spool_path"].(string); ok {
		config.SpoolPath = val
	}

	return &SLURMWorker{
		BaseRole:        roles.NewBaseRole("slurm-worker", logger),
		config:          config,
		configPath:      config.ConfigPath,
		spoolPath:       config.SpoolPath,
		mungeKeyManager: auth.NewMungeKeyManager(logger),
	}, nil
}

// Start starts the SLURM worker role
func (sw *SLURMWorker) Start(ctx context.Context, clusterState *state.ClusterState) error {
	sw.Logger().Info("Starting SLURM worker role")
	sw.clusterState = clusterState

	// Create necessary directories
	if err := sw.createDirectories(); err != nil {
		return fmt.Errorf("failed to create directories: %w", err)
	}

	// Start slurmd
	if err := sw.startSlurmd(); err != nil {
		return fmt.Errorf("failed to start slurmd: %w", err)
	}

	sw.SetRunning(true)
	sw.Logger().Info("SLURM worker role started")
	return nil
}

// Stop stops the SLURM worker role
func (sw *SLURMWorker) Stop(ctx context.Context) error {
	sw.Logger().Info("Stopping SLURM worker role")

	// Stop slurmd
	if err := sw.stopSlurmd(); err != nil {
		sw.Logger().Warnf("Error stopping slurmd: %v", err)
	}

	sw.SetRunning(false)
	return nil
}

// Reconfigure updates the configuration
func (sw *SLURMWorker) Reconfigure(clusterState *state.ClusterState) error {
	sw.Logger().Info("Reconfiguring SLURM worker")
	sw.clusterState = clusterState

	// Reload slurmd configuration
	if sw.slurmdCmd != nil && sw.slurmdCmd.Process != nil {
		sw.Logger().Info("Reloading slurmd configuration")
		// Send SIGHUP to reload config
		if err := sw.slurmdCmd.Process.Signal(os.Signal(os.Interrupt)); err != nil {
			sw.Logger().Warnf("Failed to send reload signal: %v", err)
		}
	}

	return nil
}

// HealthCheck checks if slurmd is running
func (sw *SLURMWorker) HealthCheck() error {
	if !sw.IsRunning() {
		return fmt.Errorf("SLURM worker role is not running")
	}

	if sw.slurmdCmd == nil || sw.slurmdCmd.Process == nil {
		return fmt.Errorf("slurmd process is not running")
	}

	// Check if process is still alive
	if err := sw.slurmdCmd.Process.Signal(syscall.Signal(0)); err != nil {
		return fmt.Errorf("slurmd process health check failed: %w", err)
	}

	return nil
}

// IsLeaderRequired returns false - workers don't need leadership
func (sw *SLURMWorker) IsLeaderRequired() bool {
	return false
}

// OnLeadershipChange is not used for workers
func (sw *SLURMWorker) OnLeadershipChange(isLeader bool) error {
	return nil
}

// createDirectories creates necessary directories
func (sw *SLURMWorker) createDirectories() error {
	dirs := []string{
		sw.configPath,
		sw.spoolPath,
		"/var/log/slurm",
	}

	for _, dir := range dirs {
		if err := os.MkdirAll(dir, 0755); err != nil {
			return fmt.Errorf("failed to create directory %s: %w", dir, err)
		}
	}

	return nil
}

// startSlurmd starts the slurmd daemon
func (sw *SLURMWorker) startSlurmd() error {
	sw.Logger().Info("Starting slurmd daemon")

	// Wait for slurm.conf to exist (generated by controller)
	slurmConfPath := filepath.Join(sw.configPath, "slurm.conf")
	if _, err := os.Stat(slurmConfPath); os.IsNotExist(err) {
		sw.Logger().Warn("slurm.conf not found, waiting for controller...")
		// In production, this should wait or retry
		// For now, just log and continue
	}

	// Setup munge
	if err := sw.setupMunge(); err != nil {
		return fmt.Errorf("failed to setup munge: %w", err)
	}

	// Start slurmd
	cmd := exec.Command("slurmd",
		"-D", // Foreground mode
		"-f", slurmConfPath,
	)

	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr

	if err := cmd.Start(); err != nil {
		return fmt.Errorf("failed to start slurmd: %w", err)
	}

	sw.slurmdCmd = cmd
	sw.Logger().Info("slurmd started successfully")

	return nil
}

// stopSlurmd stops the slurmd daemon
func (sw *SLURMWorker) stopSlurmd() error {
	if sw.slurmdCmd == nil || sw.slurmdCmd.Process == nil {
		return nil
	}

	sw.Logger().Info("Stopping slurmd daemon")

	// Send terminate signal
	if err := sw.slurmdCmd.Process.Signal(os.Interrupt); err != nil {
		sw.Logger().Warnf("Failed to send interrupt signal: %v", err)
		// Try kill
		if err := sw.slurmdCmd.Process.Kill(); err != nil {
			return fmt.Errorf("failed to kill slurmd: %w", err)
		}
	}

	// Wait for process to exit
	if err := sw.slurmdCmd.Wait(); err != nil {
		sw.Logger().Warnf("slurmd exit error: %v", err)
	}

	sw.slurmdCmd = nil
	sw.Logger().Info("slurmd stopped")

	return nil
}

// setupMunge ensures munge is running and configured using Raft consensus
func (sw *SLURMWorker) setupMunge() error {
	sw.Logger().Info("Setting up munge authentication via Raft")

	// Check if key already exists on disk
	if _, err := os.Stat(auth.MungeKeyPath); err == nil {
		sw.Logger().Info("Munge key found on disk, verifying against Raft state")

		// Verify the key matches what's in Raft
		if err := sw.verifyMungeKeyAgainstRaft(); err != nil {
			sw.Logger().Warnf("Munge key verification failed: %v, will fetch from Raft", err)
			// Continue to fetch from Raft
		} else {
			// Key is valid, just start munge
			return sw.mungeKeyManager.StartMungeDaemon()
		}
	}

	// Key doesn't exist on disk or verification failed - fetch from Raft
	sw.Logger().Info("Fetching munge key from Raft consensus state")

	// Retry logic for fetching munge key from Raft
	maxRetries := 20 // Increased retries since we need to wait for leader to generate
	retryDelay := 3 * time.Second

	for i := 0; i < maxRetries; i++ {
		// Check if cluster has munge key
		if !sw.clusterState.HasMungeKey() {
			sw.Logger().Warnf("Attempt %d/%d: Cluster doesn't have munge key yet, waiting for controller to generate", i+1, maxRetries)
			if i < maxRetries-1 {
				time.Sleep(retryDelay)
				continue
			}
			return fmt.Errorf("failed to get munge key after %d attempts: cluster has no munge key", maxRetries)
		}

		// Fetch from Raft
		key, hash, err := sw.mungeKeyManager.FetchFromRaft(sw.clusterState)
		if err != nil {
			sw.Logger().Warnf("Attempt %d/%d: Failed to fetch munge key from Raft: %v", i+1, maxRetries, err)
			if i < maxRetries-1 {
				time.Sleep(retryDelay)
				continue
			}
			return fmt.Errorf("failed to fetch munge key after %d attempts: %w", maxRetries, err)
		}

		sw.Logger().Infof("Fetched munge key from Raft (hash: %s)", hash[:16]+"...")

		// Write to disk
		if err := sw.mungeKeyManager.WriteMungeKey(key); err != nil {
			return fmt.Errorf("failed to write munge key to disk: %w", err)
		}

		sw.Logger().Info("Munge key fetched from Raft and written to disk successfully")

		// Start munge daemon
		return sw.mungeKeyManager.StartMungeDaemon()
	}

	return fmt.Errorf("failed to setup munge after %d retries", maxRetries)
}

// verifyMungeKeyAgainstRaft verifies the existing munge key against Raft state
func (sw *SLURMWorker) verifyMungeKeyAgainstRaft() error {
	// Check if cluster has munge key
	if !sw.clusterState.HasMungeKey() {
		return fmt.Errorf("cluster does not have munge key in Raft state")
	}

	// Get expected hash from Raft
	_, expectedHash, err := sw.clusterState.GetMungeKey()
	if err != nil {
		return fmt.Errorf("failed to get munge key from Raft: %w", err)
	}

	// Read the existing key from disk
	key, err := sw.mungeKeyManager.ReadMungeKey()
	if err != nil {
		return fmt.Errorf("failed to read munge key from disk: %w", err)
	}

	// Verify the hash
	if !sw.mungeKeyManager.VerifyMungeKey(key, expectedHash) {
		return fmt.Errorf("munge key hash verification failed")
	}

	sw.Logger().Info("Munge key verified successfully against Raft state")
	return nil
}
